{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load data and build a network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor, Lambda\n",
    "\n",
    "training_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=False,\n",
    "    transform=ToTensor()\n",
    ")\n",
    "\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=False,\n",
    "    transform=ToTensor()\n",
    ")\n",
    "bsize = 64\n",
    "train_dataloader = DataLoader(training_data, batch_size=bsize)\n",
    "test_dataloader = DataLoader(test_data, batch_size=bsize)\n",
    "\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super(NeuralNetwork,self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28*28, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "\n",
    "model = NeuralNetwork()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# setting hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-3\n",
    "batch_size = 64\n",
    "epochs = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# add  loss function and optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# define train_loop and test_loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), batch * len(X)\n",
    "            print(f\"loss: {loss:>7f} [{current:>5d}/{size:>5d}]\")\n",
    "\n",
    "def test_loop(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    test_loss, correct = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "\n",
    "    test_loss /= size\n",
    "    correct /= size\n",
    "    print(f\"test error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "init the loss function and pass the data the train_loop and test_loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "----------------------------------------\n",
      "loss: 2.303370 [    0/60000]\n",
      "loss: 2.287602 [ 6400/60000]\n",
      "loss: 2.273006 [12800/60000]\n",
      "loss: 2.271016 [19200/60000]\n",
      "loss: 2.251667 [25600/60000]\n",
      "loss: 2.248098 [32000/60000]\n",
      "loss: 2.231467 [38400/60000]\n",
      "loss: 2.210027 [44800/60000]\n",
      "loss: 2.219783 [51200/60000]\n",
      "loss: 2.204327 [57600/60000]\n",
      "test error: \n",
      " Accuracy: 59.0%, Avg loss: 0.034396 \n",
      "\n",
      "Epoch 2\n",
      "----------------------------------------\n",
      "loss: 2.191906 [    0/60000]\n",
      "loss: 2.180615 [ 6400/60000]\n",
      "loss: 2.146415 [12800/60000]\n",
      "loss: 2.164916 [19200/60000]\n",
      "loss: 2.109900 [25600/60000]\n",
      "loss: 2.119014 [32000/60000]\n",
      "loss: 2.077165 [38400/60000]\n",
      "loss: 2.040626 [44800/60000]\n",
      "loss: 2.071718 [51200/60000]\n",
      "loss: 2.042651 [57600/60000]\n",
      "test error: \n",
      " Accuracy: 59.8%, Avg loss: 0.031589 \n",
      "\n",
      "Epoch 3\n",
      "----------------------------------------\n",
      "loss: 2.014366 [    0/60000]\n",
      "loss: 1.989833 [ 6400/60000]\n",
      "loss: 1.921960 [12800/60000]\n",
      "loss: 1.973533 [19200/60000]\n",
      "loss: 1.853410 [25600/60000]\n",
      "loss: 1.900511 [32000/60000]\n",
      "loss: 1.809519 [38400/60000]\n",
      "loss: 1.761063 [44800/60000]\n",
      "loss: 1.830235 [51200/60000]\n",
      "loss: 1.789846 [57600/60000]\n",
      "test error: \n",
      " Accuracy: 59.7%, Avg loss: 0.027389 \n",
      "\n",
      "Epoch 4\n",
      "----------------------------------------\n",
      "loss: 1.750190 [    0/60000]\n",
      "loss: 1.720947 [ 6400/60000]\n",
      "loss: 1.627917 [12800/60000]\n",
      "loss: 1.717901 [19200/60000]\n",
      "loss: 1.553796 [25600/60000]\n",
      "loss: 1.669783 [32000/60000]\n",
      "loss: 1.505124 [38400/60000]\n",
      "loss: 1.486903 [44800/60000]\n",
      "loss: 1.588099 [51200/60000]\n",
      "loss: 1.557106 [57600/60000]\n",
      "test error: \n",
      " Accuracy: 60.8%, Avg loss: 0.023613 \n",
      "\n",
      "Epoch 5\n",
      "----------------------------------------\n",
      "loss: 1.507117 [    0/60000]\n",
      "loss: 1.492096 [ 6400/60000]\n",
      "loss: 1.392863 [12800/60000]\n",
      "loss: 1.514646 [19200/60000]\n",
      "loss: 1.327640 [25600/60000]\n",
      "loss: 1.508507 [32000/60000]\n",
      "loss: 1.287107 [38400/60000]\n",
      "loss: 1.308469 [44800/60000]\n",
      "loss: 1.418137 [51200/60000]\n",
      "loss: 1.410452 [57600/60000]\n",
      "test error: \n",
      " Accuracy: 62.0%, Avg loss: 0.021094 \n",
      "\n",
      "Epoch 6\n",
      "----------------------------------------\n",
      "loss: 1.337050 [    0/60000]\n",
      "loss: 1.338325 [ 6400/60000]\n",
      "loss: 1.234728 [12800/60000]\n",
      "loss: 1.382338 [19200/60000]\n",
      "loss: 1.180212 [25600/60000]\n",
      "loss: 1.394613 [32000/60000]\n",
      "loss: 1.153533 [38400/60000]\n",
      "loss: 1.198198 [44800/60000]\n",
      "loss: 1.302120 [51200/60000]\n",
      "loss: 1.312536 [57600/60000]\n",
      "test error: \n",
      " Accuracy: 62.8%, Avg loss: 0.019398 \n",
      "\n",
      "Epoch 7\n",
      "----------------------------------------\n",
      "loss: 1.222819 [    0/60000]\n",
      "loss: 1.236787 [ 6400/60000]\n",
      "loss: 1.125582 [12800/60000]\n",
      "loss: 1.291219 [19200/60000]\n",
      "loss: 1.085289 [25600/60000]\n",
      "loss: 1.308603 [32000/60000]\n",
      "loss: 1.068057 [38400/60000]\n",
      "loss: 1.126176 [44800/60000]\n",
      "loss: 1.218001 [51200/60000]\n",
      "loss: 1.241180 [57600/60000]\n",
      "test error: \n",
      " Accuracy: 64.1%, Avg loss: 0.018197 \n",
      "\n",
      "Epoch 8\n",
      "----------------------------------------\n",
      "loss: 1.141385 [    0/60000]\n",
      "loss: 1.165608 [ 6400/60000]\n",
      "loss: 1.046984 [12800/60000]\n",
      "loss: 1.225241 [19200/60000]\n",
      "loss: 1.020723 [25600/60000]\n",
      "loss: 1.243234 [32000/60000]\n",
      "loss: 1.009283 [38400/60000]\n",
      "loss: 1.073744 [44800/60000]\n",
      "loss: 1.156679 [51200/60000]\n",
      "loss: 1.188246 [57600/60000]\n",
      "test error: \n",
      " Accuracy: 65.1%, Avg loss: 0.017319 \n",
      "\n",
      "Epoch 9\n",
      "----------------------------------------\n",
      "loss: 1.079241 [    0/60000]\n",
      "loss: 1.112614 [ 6400/60000]\n",
      "loss: 0.988667 [12800/60000]\n",
      "loss: 1.177849 [19200/60000]\n",
      "loss: 0.974130 [25600/60000]\n",
      "loss: 1.194043 [32000/60000]\n",
      "loss: 0.966552 [38400/60000]\n",
      "loss: 1.037851 [44800/60000]\n",
      "loss: 1.110712 [51200/60000]\n",
      "loss: 1.147354 [57600/60000]\n",
      "test error: \n",
      " Accuracy: 66.1%, Avg loss: 0.016657 \n",
      "\n",
      "Epoch 10\n",
      "----------------------------------------\n",
      "loss: 1.030428 [    0/60000]\n",
      "loss: 1.071076 [ 6400/60000]\n",
      "loss: 0.943470 [12800/60000]\n",
      "loss: 1.142556 [19200/60000]\n",
      "loss: 0.939293 [25600/60000]\n",
      "loss: 1.155201 [32000/60000]\n",
      "loss: 0.933719 [38400/60000]\n",
      "loss: 1.012367 [44800/60000]\n",
      "loss: 1.074135 [51200/60000]\n",
      "loss: 1.114527 [57600/60000]\n",
      "test error: \n",
      " Accuracy: 67.3%, Avg loss: 0.016135 \n",
      "\n",
      "Epoch 11\n",
      "----------------------------------------\n",
      "loss: 0.989906 [    0/60000]\n",
      "loss: 1.036474 [ 6400/60000]\n",
      "loss: 0.906851 [12800/60000]\n",
      "loss: 1.113896 [19200/60000]\n",
      "loss: 0.912322 [25600/60000]\n",
      "loss: 1.123387 [32000/60000]\n",
      "loss: 0.907372 [38400/60000]\n",
      "loss: 0.993074 [44800/60000]\n",
      "loss: 1.044258 [51200/60000]\n",
      "loss: 1.086786 [57600/60000]\n",
      "test error: \n",
      " Accuracy: 68.5%, Avg loss: 0.015704 \n",
      "\n",
      "Epoch 12\n",
      "----------------------------------------\n",
      "loss: 0.955305 [    0/60000]\n",
      "loss: 1.005668 [ 6400/60000]\n",
      "loss: 0.875908 [12800/60000]\n",
      "loss: 1.090641 [19200/60000]\n",
      "loss: 0.890223 [25600/60000]\n",
      "loss: 1.096515 [32000/60000]\n",
      "loss: 0.885637 [38400/60000]\n",
      "loss: 0.977354 [44800/60000]\n",
      "loss: 1.018613 [51200/60000]\n",
      "loss: 1.063110 [57600/60000]\n",
      "test error: \n",
      " Accuracy: 69.4%, Avg loss: 0.015335 \n",
      "\n",
      "Epoch 13\n",
      "----------------------------------------\n",
      "loss: 0.925403 [    0/60000]\n",
      "loss: 0.978809 [ 6400/60000]\n",
      "loss: 0.848909 [12800/60000]\n",
      "loss: 1.071010 [19200/60000]\n",
      "loss: 0.871395 [25600/60000]\n",
      "loss: 1.072918 [32000/60000]\n",
      "loss: 0.866821 [38400/60000]\n",
      "loss: 0.964295 [44800/60000]\n",
      "loss: 0.995820 [51200/60000]\n",
      "loss: 1.042089 [57600/60000]\n",
      "test error: \n",
      " Accuracy: 70.2%, Avg loss: 0.015008 \n",
      "\n",
      "Epoch 14\n",
      "----------------------------------------\n",
      "loss: 0.898618 [    0/60000]\n",
      "loss: 0.954759 [ 6400/60000]\n",
      "loss: 0.824597 [12800/60000]\n",
      "loss: 1.054279 [19200/60000]\n",
      "loss: 0.854574 [25600/60000]\n",
      "loss: 1.051690 [32000/60000]\n",
      "loss: 0.849955 [38400/60000]\n",
      "loss: 0.952223 [44800/60000]\n",
      "loss: 0.975506 [51200/60000]\n",
      "loss: 1.023382 [57600/60000]\n",
      "test error: \n",
      " Accuracy: 70.9%, Avg loss: 0.014714 \n",
      "\n",
      "Epoch 15\n",
      "----------------------------------------\n",
      "loss: 0.874210 [    0/60000]\n",
      "loss: 0.932908 [ 6400/60000]\n",
      "loss: 0.802572 [12800/60000]\n",
      "loss: 1.039194 [19200/60000]\n",
      "loss: 0.839514 [25600/60000]\n",
      "loss: 1.032285 [32000/60000]\n",
      "loss: 0.834814 [38400/60000]\n",
      "loss: 0.941408 [44800/60000]\n",
      "loss: 0.957003 [51200/60000]\n",
      "loss: 1.006692 [57600/60000]\n",
      "test error: \n",
      " Accuracy: 71.5%, Avg loss: 0.014446 \n",
      "\n",
      "Epoch 16\n",
      "----------------------------------------\n",
      "loss: 0.851808 [    0/60000]\n",
      "loss: 0.912881 [ 6400/60000]\n",
      "loss: 0.782434 [12800/60000]\n",
      "loss: 1.025538 [19200/60000]\n",
      "loss: 0.826550 [25600/60000]\n",
      "loss: 1.014735 [32000/60000]\n",
      "loss: 0.820807 [38400/60000]\n",
      "loss: 0.931530 [44800/60000]\n",
      "loss: 0.939915 [51200/60000]\n",
      "loss: 0.991306 [57600/60000]\n",
      "test error: \n",
      " Accuracy: 72.2%, Avg loss: 0.014199 \n",
      "\n",
      "Epoch 17\n",
      "----------------------------------------\n",
      "loss: 0.831313 [    0/60000]\n",
      "loss: 0.894173 [ 6400/60000]\n",
      "loss: 0.763810 [12800/60000]\n",
      "loss: 1.012670 [19200/60000]\n",
      "loss: 0.814675 [25600/60000]\n",
      "loss: 0.998639 [32000/60000]\n",
      "loss: 0.808010 [38400/60000]\n",
      "loss: 0.922827 [44800/60000]\n",
      "loss: 0.924263 [51200/60000]\n",
      "loss: 0.977193 [57600/60000]\n",
      "test error: \n",
      " Accuracy: 72.6%, Avg loss: 0.013970 \n",
      "\n",
      "Epoch 18\n",
      "----------------------------------------\n",
      "loss: 0.812777 [    0/60000]\n",
      "loss: 0.876122 [ 6400/60000]\n",
      "loss: 0.746874 [12800/60000]\n",
      "loss: 1.000870 [19200/60000]\n",
      "loss: 0.804215 [25600/60000]\n",
      "loss: 0.983512 [32000/60000]\n",
      "loss: 0.796327 [38400/60000]\n",
      "loss: 0.915421 [44800/60000]\n",
      "loss: 0.910470 [51200/60000]\n",
      "loss: 0.964128 [57600/60000]\n",
      "test error: \n",
      " Accuracy: 73.1%, Avg loss: 0.013758 \n",
      "\n",
      "Epoch 19\n",
      "----------------------------------------\n",
      "loss: 0.795752 [    0/60000]\n",
      "loss: 0.859485 [ 6400/60000]\n",
      "loss: 0.731278 [12800/60000]\n",
      "loss: 0.989791 [19200/60000]\n",
      "loss: 0.794856 [25600/60000]\n",
      "loss: 0.969770 [32000/60000]\n",
      "loss: 0.785567 [38400/60000]\n",
      "loss: 0.908532 [44800/60000]\n",
      "loss: 0.897471 [51200/60000]\n",
      "loss: 0.951668 [57600/60000]\n",
      "test error: \n",
      " Accuracy: 73.4%, Avg loss: 0.013562 \n",
      "\n",
      "Epoch 20\n",
      "----------------------------------------\n",
      "loss: 0.780045 [    0/60000]\n",
      "loss: 0.843873 [ 6400/60000]\n",
      "loss: 0.716912 [12800/60000]\n",
      "loss: 0.979052 [19200/60000]\n",
      "loss: 0.786074 [25600/60000]\n",
      "loss: 0.956901 [32000/60000]\n",
      "loss: 0.775667 [38400/60000]\n",
      "loss: 0.902418 [44800/60000]\n",
      "loss: 0.886199 [51200/60000]\n",
      "loss: 0.939977 [57600/60000]\n",
      "test error: \n",
      " Accuracy: 73.7%, Avg loss: 0.013378 \n",
      "\n",
      "Epoch 21\n",
      "----------------------------------------\n",
      "loss: 0.765608 [    0/60000]\n",
      "loss: 0.829439 [ 6400/60000]\n",
      "loss: 0.703726 [12800/60000]\n",
      "loss: 0.968886 [19200/60000]\n",
      "loss: 0.778092 [25600/60000]\n",
      "loss: 0.945010 [32000/60000]\n",
      "loss: 0.766647 [38400/60000]\n",
      "loss: 0.897028 [44800/60000]\n",
      "loss: 0.876216 [51200/60000]\n",
      "loss: 0.929107 [57600/60000]\n",
      "test error: \n",
      " Accuracy: 73.9%, Avg loss: 0.013207 \n",
      "\n",
      "Epoch 22\n",
      "----------------------------------------\n",
      "loss: 0.752183 [    0/60000]\n",
      "loss: 0.815977 [ 6400/60000]\n",
      "loss: 0.691714 [12800/60000]\n",
      "loss: 0.959258 [19200/60000]\n",
      "loss: 0.770499 [25600/60000]\n",
      "loss: 0.934448 [32000/60000]\n",
      "loss: 0.757922 [38400/60000]\n",
      "loss: 0.892159 [44800/60000]\n",
      "loss: 0.867377 [51200/60000]\n",
      "loss: 0.918436 [57600/60000]\n",
      "test error: \n",
      " Accuracy: 74.1%, Avg loss: 0.013047 \n",
      "\n",
      "Epoch 23\n",
      "----------------------------------------\n",
      "loss: 0.739785 [    0/60000]\n",
      "loss: 0.803856 [ 6400/60000]\n",
      "loss: 0.680712 [12800/60000]\n",
      "loss: 0.949867 [19200/60000]\n",
      "loss: 0.763162 [25600/60000]\n",
      "loss: 0.924419 [32000/60000]\n",
      "loss: 0.750086 [38400/60000]\n",
      "loss: 0.887953 [44800/60000]\n",
      "loss: 0.859448 [51200/60000]\n",
      "loss: 0.908351 [57600/60000]\n",
      "test error: \n",
      " Accuracy: 74.3%, Avg loss: 0.012897 \n",
      "\n",
      "Epoch 24\n",
      "----------------------------------------\n",
      "loss: 0.728439 [    0/60000]\n",
      "loss: 0.791613 [ 6400/60000]\n",
      "loss: 0.670707 [12800/60000]\n",
      "loss: 0.940676 [19200/60000]\n",
      "loss: 0.756620 [25600/60000]\n",
      "loss: 0.915367 [32000/60000]\n",
      "loss: 0.742745 [38400/60000]\n",
      "loss: 0.884050 [44800/60000]\n",
      "loss: 0.852368 [51200/60000]\n",
      "loss: 0.898634 [57600/60000]\n",
      "test error: \n",
      " Accuracy: 74.5%, Avg loss: 0.012756 \n",
      "\n",
      "Epoch 25\n",
      "----------------------------------------\n",
      "loss: 0.717842 [    0/60000]\n",
      "loss: 0.780114 [ 6400/60000]\n",
      "loss: 0.661519 [12800/60000]\n",
      "loss: 0.931319 [19200/60000]\n",
      "loss: 0.750490 [25600/60000]\n",
      "loss: 0.907022 [32000/60000]\n",
      "loss: 0.735965 [38400/60000]\n",
      "loss: 0.880626 [44800/60000]\n",
      "loss: 0.846331 [51200/60000]\n",
      "loss: 0.889226 [57600/60000]\n",
      "test error: \n",
      " Accuracy: 74.7%, Avg loss: 0.012624 \n",
      "\n",
      "Epoch 26\n",
      "----------------------------------------\n",
      "loss: 0.707769 [    0/60000]\n",
      "loss: 0.769329 [ 6400/60000]\n",
      "loss: 0.653119 [12800/60000]\n",
      "loss: 0.922341 [19200/60000]\n",
      "loss: 0.744437 [25600/60000]\n",
      "loss: 0.898916 [32000/60000]\n",
      "loss: 0.729642 [38400/60000]\n",
      "loss: 0.878027 [44800/60000]\n",
      "loss: 0.840190 [51200/60000]\n",
      "loss: 0.880129 [57600/60000]\n",
      "test error: \n",
      " Accuracy: 74.9%, Avg loss: 0.012499 \n",
      "\n",
      "Epoch 27\n",
      "----------------------------------------\n",
      "loss: 0.698404 [    0/60000]\n",
      "loss: 0.759211 [ 6400/60000]\n",
      "loss: 0.645082 [12800/60000]\n",
      "loss: 0.913550 [19200/60000]\n",
      "loss: 0.738512 [25600/60000]\n",
      "loss: 0.891537 [32000/60000]\n",
      "loss: 0.723780 [38400/60000]\n",
      "loss: 0.875698 [44800/60000]\n",
      "loss: 0.834890 [51200/60000]\n",
      "loss: 0.871365 [57600/60000]\n",
      "test error: \n",
      " Accuracy: 75.1%, Avg loss: 0.012382 \n",
      "\n",
      "Epoch 28\n",
      "----------------------------------------\n",
      "loss: 0.689569 [    0/60000]\n",
      "loss: 0.749985 [ 6400/60000]\n",
      "loss: 0.637614 [12800/60000]\n",
      "loss: 0.905090 [19200/60000]\n",
      "loss: 0.732935 [25600/60000]\n",
      "loss: 0.884811 [32000/60000]\n",
      "loss: 0.718217 [38400/60000]\n",
      "loss: 0.873435 [44800/60000]\n",
      "loss: 0.829841 [51200/60000]\n",
      "loss: 0.862881 [57600/60000]\n",
      "test error: \n",
      " Accuracy: 75.3%, Avg loss: 0.012271 \n",
      "\n",
      "Epoch 29\n",
      "----------------------------------------\n",
      "loss: 0.681246 [    0/60000]\n",
      "loss: 0.741209 [ 6400/60000]\n",
      "loss: 0.630716 [12800/60000]\n",
      "loss: 0.896860 [19200/60000]\n",
      "loss: 0.727695 [25600/60000]\n",
      "loss: 0.878581 [32000/60000]\n",
      "loss: 0.713083 [38400/60000]\n",
      "loss: 0.871288 [44800/60000]\n",
      "loss: 0.824525 [51200/60000]\n",
      "loss: 0.854689 [57600/60000]\n",
      "test error: \n",
      " Accuracy: 75.4%, Avg loss: 0.012168 \n",
      "\n",
      "Epoch 30\n",
      "----------------------------------------\n",
      "loss: 0.673194 [    0/60000]\n",
      "loss: 0.733096 [ 6400/60000]\n",
      "loss: 0.624301 [12800/60000]\n",
      "loss: 0.889171 [19200/60000]\n",
      "loss: 0.722122 [25600/60000]\n",
      "loss: 0.872932 [32000/60000]\n",
      "loss: 0.708097 [38400/60000]\n",
      "loss: 0.869213 [44800/60000]\n",
      "loss: 0.820253 [51200/60000]\n",
      "loss: 0.846781 [57600/60000]\n",
      "test error: \n",
      " Accuracy: 75.5%, Avg loss: 0.012070 \n",
      "\n",
      "Epoch 31\n",
      "----------------------------------------\n",
      "loss: 0.665542 [    0/60000]\n",
      "loss: 0.725653 [ 6400/60000]\n",
      "loss: 0.618270 [12800/60000]\n",
      "loss: 0.881582 [19200/60000]\n",
      "loss: 0.716872 [25600/60000]\n",
      "loss: 0.867424 [32000/60000]\n",
      "loss: 0.703585 [38400/60000]\n",
      "loss: 0.867362 [44800/60000]\n",
      "loss: 0.816160 [51200/60000]\n",
      "loss: 0.839211 [57600/60000]\n",
      "test error: \n",
      " Accuracy: 75.7%, Avg loss: 0.011979 \n",
      "\n",
      "Epoch 32\n",
      "----------------------------------------\n",
      "loss: 0.658295 [    0/60000]\n",
      "loss: 0.718798 [ 6400/60000]\n",
      "loss: 0.612633 [12800/60000]\n",
      "loss: 0.874107 [19200/60000]\n",
      "loss: 0.711794 [25600/60000]\n",
      "loss: 0.861811 [32000/60000]\n",
      "loss: 0.699047 [38400/60000]\n",
      "loss: 0.865874 [44800/60000]\n",
      "loss: 0.812314 [51200/60000]\n",
      "loss: 0.831934 [57600/60000]\n",
      "test error: \n",
      " Accuracy: 75.8%, Avg loss: 0.011893 \n",
      "\n",
      "Epoch 33\n",
      "----------------------------------------\n",
      "loss: 0.651400 [    0/60000]\n",
      "loss: 0.712389 [ 6400/60000]\n",
      "loss: 0.607462 [12800/60000]\n",
      "loss: 0.867281 [19200/60000]\n",
      "loss: 0.707377 [25600/60000]\n",
      "loss: 0.856867 [32000/60000]\n",
      "loss: 0.695026 [38400/60000]\n",
      "loss: 0.864785 [44800/60000]\n",
      "loss: 0.809017 [51200/60000]\n",
      "loss: 0.824971 [57600/60000]\n",
      "test error: \n",
      " Accuracy: 75.9%, Avg loss: 0.011812 \n",
      "\n",
      "Epoch 34\n",
      "----------------------------------------\n",
      "loss: 0.644832 [    0/60000]\n",
      "loss: 0.706443 [ 6400/60000]\n",
      "loss: 0.602522 [12800/60000]\n",
      "loss: 0.860723 [19200/60000]\n",
      "loss: 0.702267 [25600/60000]\n",
      "loss: 0.852359 [32000/60000]\n",
      "loss: 0.691073 [38400/60000]\n",
      "loss: 0.863781 [44800/60000]\n",
      "loss: 0.805996 [51200/60000]\n",
      "loss: 0.818078 [57600/60000]\n",
      "test error: \n",
      " Accuracy: 76.0%, Avg loss: 0.011736 \n",
      "\n",
      "Epoch 35\n",
      "----------------------------------------\n",
      "loss: 0.638615 [    0/60000]\n",
      "loss: 0.700821 [ 6400/60000]\n",
      "loss: 0.597854 [12800/60000]\n",
      "loss: 0.854365 [19200/60000]\n",
      "loss: 0.697066 [25600/60000]\n",
      "loss: 0.847989 [32000/60000]\n",
      "loss: 0.687371 [38400/60000]\n",
      "loss: 0.863319 [44800/60000]\n",
      "loss: 0.802583 [51200/60000]\n",
      "loss: 0.811527 [57600/60000]\n",
      "test error: \n",
      " Accuracy: 76.1%, Avg loss: 0.011665 \n",
      "\n",
      "Epoch 36\n",
      "----------------------------------------\n",
      "loss: 0.632690 [    0/60000]\n",
      "loss: 0.695628 [ 6400/60000]\n",
      "loss: 0.593517 [12800/60000]\n",
      "loss: 0.848250 [19200/60000]\n",
      "loss: 0.692296 [25600/60000]\n",
      "loss: 0.843753 [32000/60000]\n",
      "loss: 0.682935 [38400/60000]\n",
      "loss: 0.862748 [44800/60000]\n",
      "loss: 0.799509 [51200/60000]\n",
      "loss: 0.805297 [57600/60000]\n",
      "test error: \n",
      " Accuracy: 76.2%, Avg loss: 0.011599 \n",
      "\n",
      "Epoch 37\n",
      "----------------------------------------\n",
      "loss: 0.626993 [    0/60000]\n",
      "loss: 0.690967 [ 6400/60000]\n",
      "loss: 0.589107 [12800/60000]\n",
      "loss: 0.842479 [19200/60000]\n",
      "loss: 0.688118 [25600/60000]\n",
      "loss: 0.839582 [32000/60000]\n",
      "loss: 0.678002 [38400/60000]\n",
      "loss: 0.862216 [44800/60000]\n",
      "loss: 0.796988 [51200/60000]\n",
      "loss: 0.799175 [57600/60000]\n",
      "test error: \n",
      " Accuracy: 76.2%, Avg loss: 0.011536 \n",
      "\n",
      "Epoch 38\n",
      "----------------------------------------\n",
      "loss: 0.621443 [    0/60000]\n",
      "loss: 0.686665 [ 6400/60000]\n",
      "loss: 0.585076 [12800/60000]\n",
      "loss: 0.836796 [19200/60000]\n",
      "loss: 0.683525 [25600/60000]\n",
      "loss: 0.836390 [32000/60000]\n",
      "loss: 0.673004 [38400/60000]\n",
      "loss: 0.861812 [44800/60000]\n",
      "loss: 0.794462 [51200/60000]\n",
      "loss: 0.793511 [57600/60000]\n",
      "test error: \n",
      " Accuracy: 76.4%, Avg loss: 0.011478 \n",
      "\n",
      "Epoch 39\n",
      "----------------------------------------\n",
      "loss: 0.616107 [    0/60000]\n",
      "loss: 0.682702 [ 6400/60000]\n",
      "loss: 0.581229 [12800/60000]\n",
      "loss: 0.831355 [19200/60000]\n",
      "loss: 0.678804 [25600/60000]\n",
      "loss: 0.832353 [32000/60000]\n",
      "loss: 0.668874 [38400/60000]\n",
      "loss: 0.860857 [44800/60000]\n",
      "loss: 0.792271 [51200/60000]\n",
      "loss: 0.788018 [57600/60000]\n",
      "test error: \n",
      " Accuracy: 76.4%, Avg loss: 0.011422 \n",
      "\n",
      "Epoch 40\n",
      "----------------------------------------\n",
      "loss: 0.611000 [    0/60000]\n",
      "loss: 0.679050 [ 6400/60000]\n",
      "loss: 0.577588 [12800/60000]\n",
      "loss: 0.825776 [19200/60000]\n",
      "loss: 0.673998 [25600/60000]\n",
      "loss: 0.829292 [32000/60000]\n",
      "loss: 0.663940 [38400/60000]\n",
      "loss: 0.860419 [44800/60000]\n",
      "loss: 0.789890 [51200/60000]\n",
      "loss: 0.782606 [57600/60000]\n",
      "test error: \n",
      " Accuracy: 76.5%, Avg loss: 0.011369 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "epochs = 40\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n----------------------------------------\")\n",
    "    train_loop(train_dataloader, model, loss_fn, optimizer)\n",
    "    test_loop(test_dataloader, model, loss_fn)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"data/model_1.pth\")\n",
    "torch.save(model, \"data/model_all.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
      "    (5): ReLU()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save and load model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.onnx as onnx\n",
    "import torchvision.models as models\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving and loading only model weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.vgg16(pretrained=True)\n",
    "torch.save(model.state_dict(), 'data/model_weights.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.vgg16()\n",
    "model.load_state_dict(torch.load(\"data/model_weights.pth\"))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Note:** Be sure to call `model.eval()` method before inferencing to set the dropout and batch normalization layers to evaluation mode. Failing to do this will yield inconsistent inference results.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# saving and loading models with shapes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, \"data/vgg_model.pth\")\n",
    "model = torch.load(\"data/vgg_model.pth\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exporting the model to ONNX\n",
    "\n",
    "PyTorch also has native ONNX export support. Given the dynamic nature of the PyTorch execution graph, however, the export process must traverse the execution graph to produce a persisted ONNX model. For this reason, a test variable of the appropriate size should be passed in to the export routine (in our case, we will create a dummy zero tensor of the correct size):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_image = torch.zeros((1,3,224,224))\n",
    "onnx.export(model, input_image, 'data/model.onnx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean of 10 runs: 1.74857s\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "np.random.seed(42)\n",
    "a = np.random.uniform(size=(300, 300))\n",
    "runtimes = 10\n",
    "\n",
    "timecosts = []\n",
    "for _ in range(runtimes):\n",
    "    s_time = time.time()\n",
    "    for i in range(100):\n",
    "        a += 1\n",
    "        np.linalg.svd(a)\n",
    "    timecosts.append(time.time() - s_time)\n",
    "\n",
    "print(f'mean of {runtimes} runs: {np.mean(timecosts):.5f}s')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "665c9362c857ab9fab2bd3645e927e21c39961eb9c03ec3f963d4db5fcabf320"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('torch': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
